{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3614442-a3da-403f-86c4-b3679c3c4e07",
   "metadata": {},
   "source": [
    "# Extracting PD-like templates from Wikimedia Commons Files\n",
    "This notebook retrieves all files in the category `Media from Delpher` on Wikimedia Commons, \n",
    "then checks the wikitext of each file for public domain (PD) templates (templates that tyoically start with `{{PD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5165a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Fetching files in category 'Media from Delpher' excluding 'Scans from the Internet Archive'...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 484\u001b[39m\n\u001b[32m    482\u001b[39m     include_term = \u001b[33m\"\u001b[39m\u001b[33mMedia from Delpher\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m     exclude_term = \u001b[33m\"\u001b[39m\u001b[33mScans from the Internet Archive\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[43mprocess_templates_for_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    486\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 430\u001b[39m, in \u001b[36mprocess_templates_for_category\u001b[39m\u001b[34m(include_term, exclude_term)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[33;03mProcesses Wikimedia Commons files from a specific category and extracts relevant metadata.\u001b[39;00m\n\u001b[32m    410\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    427\u001b[39m \u001b[33;03m    None\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     file_titles = \u001b[43msearch_files_from_category_excluding_term\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     file_titles = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(file_titles))  \u001b[38;5;66;03m# Remove duplicates\u001b[39;00m\n\u001b[32m    432\u001b[39m     records = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 297\u001b[39m, in \u001b[36msearch_files_from_category_excluding_term\u001b[39m\u001b[34m(include_term, exclude_term, limit)\u001b[39m\n\u001b[32m    287\u001b[39m params = {\n\u001b[32m    288\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    289\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    294\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msroffset\u001b[39m\u001b[33m\"\u001b[39m: offset\n\u001b[32m    295\u001b[39m }\n\u001b[32m    296\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mOlafJanssenBot/1.0 (https://commons.wikimedia.org/wiki/User:OlafJanssenBot; Python script)\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEARCH_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m.json()\n\u001b[32m    298\u001b[39m results = response.get(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m    299\u001b[39m all_titles.extend([\u001b[33m\"\u001b[39m\u001b[33mFile:\u001b[39m\u001b[33m\"\u001b[39m + r[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33mFile:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/paws/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract PD-like templates from Wikimedia Commons files in 'Media from Delpher' category\n",
    "=======================================================================================\n",
    "\n",
    "Overview:\n",
    "---------\n",
    "This script identifies and extracts potentially Public Domain (PD) or PD-like licensing templates\n",
    "from files hosted on Wikimedia Commons, specifically those categorized under:\n",
    "\n",
    "    - Category:Media from Delpher\n",
    "    - But excluding: Category:Scans from the Internet Archive\n",
    "\n",
    "The goal is to help detect files with licensing metadata that suggest they are in the public domain,\n",
    "but which are not explicitly tagged using standard Internet Archive or PD templates.\n",
    "\n",
    "How it works:\n",
    "-------------\n",
    "1. **File Discovery**\n",
    "   Uses the MediaWiki API to query Commons for files in the target category (`Media from Delpher`)\n",
    "   while excluding those in a known-safe PD category (`Scans from the Internet Archive`).\n",
    "\n",
    "2. **Wikitext Retrieval**\n",
    "   For each matching file, the script fetches the raw wikitext (template code, metadata, and fields).\n",
    "\n",
    "3. **Template Extraction**\n",
    "   The script identifies templates from two sources:\n",
    "   - Top-level templates (directly used on the file page)\n",
    "   - Templates embedded within the `|permission=` or `|date=` fields of wrapper templates like:\n",
    "     `{{Information}}`, `{{Book}}`, `{{Photograph}}`, or `{{Artwork}}`\n",
    "\n",
    "   Templates are filtered using several exclusion rules:\n",
    "   - Known irrelevant or decorative templates (see `EXCLUDED_TEMPLATES`)\n",
    "   - Templates with namespaced prefixes (e.g., `User:`, `Creator:`)\n",
    "   - Language-tagging templates like `{{en}}`, `{{nl}}`, etc.\n",
    "   - Utility templates like `{{DEFAULTSORT}}` or `{{ucfirst}}`\n",
    "\n",
    "4. **Date Extraction**\n",
    "   Attempts to derive a simplified creation or publication date from template metadata:\n",
    "   - Recognizes formats like `{{circa|1930}}`, `{{other date|between|1920|1935}}`, or `1935-06-01`\n",
    "   - If no date is available, leaves field blank or as `\"Unknown\"`\n",
    "\n",
    "5. **Output**\n",
    "   - Console output: File URL, parsed date, detected template names with links\n",
    "   - Excel file: A table with rows per file and columns for:\n",
    "     - File URL\n",
    "     - Parsed date\n",
    "     - Number of templates\n",
    "     - Each template name and a link to its documentation page\n",
    "\n",
    "Configuration & Customization:\n",
    "------------------------------\n",
    "- To change which files are analyzed, modify:\n",
    "    `include_term = \"Media from Delpher\"`\n",
    "    `exclude_term = \"Scans from the Internet Archive\"`\n",
    "\n",
    "- Output is saved as:\n",
    "    `Media_from_Delpher_commons_templates_output_<DATE>.xlsx`\n",
    "\n",
    "- You can limit the number of processed files for testing by modifying:\n",
    "    `limit=20` in the `search_files_from_category_excluding_term()` function call.\n",
    "\n",
    "Requirements:\n",
    "-------------\n",
    "- Python 3.7+\n",
    "- `requests`\n",
    "- `pandas`\n",
    "- `openpyxl` (for Excel export)\n",
    "\n",
    "Author:\n",
    "-------\n",
    "- Olaf Janssen, Wikimedia coordinator @KB national library of the Netherlands (via ChatGPT)\n",
    "- Last updated: 9 April 2025\n",
    "- User-Agent: OlafJanssenBot/1.0\n",
    "\n",
    "License:\n",
    "--------\n",
    "This script is released into the public domain. You may freely use, adapt, and redistribute it.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import openpyxl\n",
    "\n",
    "# List of templates to exclude (case-insensitive, supports wildcards for regex filtering)\n",
    "EXCLUDED_TEMPLATES = {\n",
    "    '1937',\n",
    "    '1937 03 17',\n",
    "    'after',\n",
    "    'anonymous',\n",
    "    'author',\n",
    "    'before',\n",
    "    'between',\n",
    "    'bijbelsche kunst',\n",
    "    'bildindex',\n",
    "    'boijmansonline',\n",
    "    'booknavibar',\n",
    "    'border is intentional',\n",
    "    'chefs d\\'oeuvre de la collection d.g. van beuningen',\n",
    "    'cite news',\n",
    "    'circa',\n",
    "    'collective work',\n",
    "    'complex date',\n",
    "    'creator',\n",
    "    'crop for wikidata',\n",
    "    'date',\n",
    "    'dead link',\n",
    "    'de collectie verrijkt',\n",
    "    'de j√©r√¥me bosch √† rembrandt, peintures et dessins du mus√©e boymans de rotterdam',\n",
    "    'de minimis',\n",
    "    'deminimis',\n",
    "    'delpher',\n",
    "    'djvu',\n",
    "    'daumier register',\n",
    "    'dutch art 1450‚Äì1900',\n",
    "    'extracted',\n",
    "    'extracted from',\n",
    "    'fop-pakistan',\n",
    "    'fourcaud (1)',\n",
    "    'fraenger',\n",
    "    'friedl√§nder',\n",
    "    'haverman, hendrik johannes',\n",
    "    'het wonder, miracula christi',\n",
    "    'hieronymus bosch, the complete paintings and drawings',\n",
    "    'hieronymus bosch, visions of genius',\n",
    "    'honderd jaar museum boymans, rotterdam, meesterwerken uit de verzameling d.g. van beuningen',\n",
    "    'image extracted',\n",
    "    'imagenote',\n",
    "    'imagenoteend',\n",
    "    'insignia',\n",
    "    'jeroen bosch, noord-nederlandsche primitieven',\n",
    "    'j√©r√¥me bosch (fierens-vevaert)',\n",
    "    'jheronimus bosch (1967)',\n",
    "    'jheronimus bosch (2001)',\n",
    "    'jheronimus bosch alle schilderijen en tekeningen',\n",
    "    'kersttentoonstelling (1927-1928)',\n",
    "    'kik-irpa',\n",
    "    'kunstschatten uit nederlandse verzamelingen',\n",
    "    'la collection goudstikker (june 1927)',\n",
    "    'langswitch',\n",
    "    'les primitifs flamands',\n",
    "    'location',\n",
    "    'marijnissen',\n",
    "    'object location',\n",
    "    'onze afgevaardigden 1909',\n",
    "    'onze afgevaardigden 1913',\n",
    "    'onze musici',\n",
    "    'onze musici (1923)',\n",
    "    'original',\n",
    "    'original caption',\n",
    "    'original description',\n",
    "    'original description page',\n",
    "    'other date',\n",
    "    'otherdate',\n",
    "    'otherversion',\n",
    "    'other version',\n",
    "    'p-page',\n",
    "    'pd-algorithm',\n",
    "    'provenanceevent',\n",
    "    'retouched',\n",
    "    'retouchedpicture',\n",
    "    'retouched picture',\n",
    "    'rijksmonument',\n",
    "    'rkdimages',\n",
    "    'see more images',\n",
    "    'size',\n",
    "    'superseded',\n",
    "    'taken on',\n",
    "    'technique',\n",
    "    'tentoonstelling hieronymus bosch (1930)',\n",
    "    'tentoonstelling van oude kunst door de vereeniging van handelaren in oude kunst in nederland',\n",
    "    'tolnay',\n",
    "    'transferred from',\n",
    "    'ucfirst',\n",
    "    'uncategorized',\n",
    "    'uploaded from mobile',\n",
    "    'uploaded with derivativefx',\n",
    "    'user',\n",
    "    'van eyck to bruegel, 1400-1550',\n",
    "    'verzameling f. koenigs',\n",
    "    'vlaamsche kunst',\n",
    "    'wga'\n",
    "}\n",
    "\n",
    "WRAPPER_TEMPLATES = ['Information', 'information','Photograph','photograph', 'Artwork', 'artwork', 'Art Photo','Art photo','Book','book']\n",
    "\n",
    "LANGUAGE_TEMPLATE_PATTERN = re.compile(r'^[a-z]{2,3}$', re.IGNORECASE)\n",
    "ONZE_PATTERN = re.compile(r'^onze afgevaardigden.*$', re.IGNORECASE)\n",
    "DEFAULTSORT_PATTERN = re.compile(r'^defaultsort[: ]', re.IGNORECASE)\n",
    "COLON_TEMPLATE_PATTERN = re.compile(r'^.*:.*$') #{{Creator:Hendrik Jan Bulthuis}}, {{User:Wdwdbot}}, {{ucfirst: {{Anonymous}} or {{Template:Something}}\n",
    "\n",
    "def extract_year_from_date_string(date_str):\n",
    "    \"\"\"\n",
    "    Parses a date string from Commons wikitext and extracts a simplified year or century.\n",
    "\n",
    "    Handles:\n",
    "    - {{circa|1939}}, {{taken on|1918-12-21}}, {{other date|between|...}}\n",
    "    - Numeric formats like \"19350601\", \"1935-06\", etc.\n",
    "    - Templates wrapped in {{ucfirst:...}} and similar\n",
    "\n",
    "    Returns:\n",
    "        str: A human-readable date (e.g., \"1939\", \"20th century\", \"Unknown\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lower = date_str.lower()\n",
    "\n",
    "        # Strip nested ucfirst template\n",
    "        nested_match = re.search(r'\\{\\{[Uu][Cc]first:\\s*(\\{\\{.*?\\}\\})\\s*\\}\\}', date_str, re.IGNORECASE)\n",
    "        if nested_match:\n",
    "            date_str = nested_match.group(1)\n",
    "\n",
    "        # Existing special templates\n",
    "        if '{{complex date' in lower:\n",
    "            century_match = re.search(r'\\|\\s*century\\s*\\|\\s*(\\d{1,2})', date_str, re.IGNORECASE)\n",
    "            adj_match = re.search(r'\\|\\s*adj1\\s*=\\s*(\\w+)', date_str, re.IGNORECASE)\n",
    "            if century_match:\n",
    "                century = int(century_match.group(1))\n",
    "                adjective = adj_match.group(1).capitalize() + ' ' if adj_match else ''\n",
    "                return f\"{adjective}{century}th century\"\n",
    "\n",
    "        circa_match = re.search(r'\\{\\{[Cc]irca\\|(\\d{4})\\}\\}', date_str, re.IGNORECASE)\n",
    "        if circa_match:\n",
    "            return circa_match.group(1)\n",
    "\n",
    "        century_match = re.search(r'\\{\\{\\s*[Oo]ther date\\s*\\|\\s*century\\s*\\|\\s*(\\d{1,2})', date_str, re.IGNORECASE)\n",
    "        if century_match:\n",
    "            return f\"{century_match.group(1)}th century\"\n",
    "\n",
    "        if re.search(r'\\{\\{\\s*[Oo]ther date\\s*\\|\\s*\\?\\s*\\}\\}', date_str, re.IGNORECASE):\n",
    "            return \"Unknown\"\n",
    "\n",
    "        taken_on_match = re.search(r'\\{\\{\\s*[Tt]aken on\\s*\\|\\s*(\\d{4})-\\d{2}-\\d{2}', date_str, re.IGNORECASE)\n",
    "        if taken_on_match:\n",
    "            return taken_on_match.group(1)\n",
    "\n",
    "        between_match = re.search(r'\\{\\{\\s*[Oo]ther date\\s*\\|\\s*between\\s*\\|\\s*(\\d{4})\\s*\\|\\s*(\\d{4})\\s*\\}\\}', date_str, re.IGNORECASE)\n",
    "        if between_match:\n",
    "            return between_match.group(2)\n",
    "\n",
    "        # NEW: handle full or partial numeric formats\n",
    "        compact_date = re.match(r'(\\d{4})[-/]?\\d{0,4}', date_str)\n",
    "        if compact_date:\n",
    "            return compact_date.group(1)\n",
    "\n",
    "        # Fallback: any 4-digit year\n",
    "        year_match = re.search(r'(\\d{4})', date_str)\n",
    "        if year_match:\n",
    "            return year_match.group(1)\n",
    "\n",
    "        return date_str.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting year from date: {e}\")\n",
    "        return date_str.strip()\n",
    "\n",
    "\n",
    "\n",
    "def is_excluded_template(name):\n",
    "    \"\"\"\n",
    "    Determines whether a template name should be excluded based on known irrelevant, generic,\n",
    "    or colon-containing patterns (e.g., {{User:...}}, {{Creator:...}}, {{ucfirst:...}}).\n",
    "\n",
    "    This function checks if the given template name:\n",
    "    - Is in the predefined `EXCLUDED_TEMPLATES` set (case-insensitive)\n",
    "    - Matches known patterns like {{DEFAULTSORT}}, {{onze afgevaardigden...}}, or language codes (e.g., \"en\", \"nl\")\n",
    "    - Contains a colon (used for namespaced or nested templates)\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the template to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the template should be excluded, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        name_lc = name.lower()\n",
    "        return (\n",
    "            name_lc in EXCLUDED_TEMPLATES\n",
    "            or DEFAULTSORT_PATTERN.match(name_lc)\n",
    "            or ONZE_PATTERN.match(name_lc)\n",
    "            or LANGUAGE_TEMPLATE_PATTERN.match(name_lc)\n",
    "            or COLON_TEMPLATE_PATTERN.match(name)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking if template is excluded ({name}): {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_wikitext(title):\n",
    "    \"\"\"\n",
    "    Retrieves the raw wikitext of a Wikimedia Commons page by its title.\n",
    "\n",
    "    Uses the MediaWiki API (`action=parse`) to fetch the 'wikitext' property of the specified page.\n",
    "    If the request fails or the expected response format is missing, returns an empty string.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the Wikimedia Commons page (e.g., \"File:Example.jpg\").\n",
    "\n",
    "    Returns:\n",
    "        str: The raw wikitext of the page, or an empty string if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = 'https://commons.wikimedia.org/w/api.php'\n",
    "        params = {\n",
    "            'action': 'parse',\n",
    "            'page': title,\n",
    "            'prop': 'wikitext',\n",
    "            'format': 'json'\n",
    "        }\n",
    "        headers = {\"User-Agent\": \"OlafJanssenBot/1.0 (https://commons.wikimedia.org/wiki/User:OlafJanssenBot; Python script)\"}\n",
    "        response = requests.get(url, params=params, headers=headers).json()\n",
    "        return response['parse']['wikitext']['*']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching wikitext for {title}: {e}\")\n",
    "        return ''\n",
    "\n",
    "\n",
    "\n",
    "def search_files_from_category_excluding_term(include_term, exclude_term, limit=500):\n",
    "    \"\"\"\n",
    "    Searches Wikimedia Commons for files in one category while excluding files from another.\n",
    "\n",
    "    Uses the MediaWiki search API to find files (namespace 6) that are in the `include_term` category\n",
    "    but not in the `exclude_term` category. Fetches results in batches using pagination.\n",
    "\n",
    "    Args:\n",
    "        include_term (str): The name of the category to include (e.g., \"Media from Delpher\").\n",
    "        exclude_term (str): The name of the category to exclude (e.g., \"Scans from the Internet Archive\").\n",
    "        limit (int): The number of results to retrieve per API call (max 500).\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of file titles (e.g., \"File:Example.jpg\"). Empty if the request fails.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Fetching files in category '{include_term}' excluding '{exclude_term}'...\")\n",
    "    try:\n",
    "        SEARCH_URL = \"https://commons.wikimedia.org/w/api.php\"\n",
    "        offset = 0\n",
    "        all_titles = []\n",
    "\n",
    "        while True:\n",
    "            params = {\n",
    "                \"action\": \"query\",\n",
    "                \"format\": \"json\",\n",
    "                \"list\": \"search\",\n",
    "                \"srsearch\": f\"incategory:\\\"{include_term}\\\" -incategory:\\\"{exclude_term}\\\"\",\n",
    "                \"srlimit\": limit,\n",
    "                \"srnamespace\": 6,\n",
    "                \"sroffset\": offset\n",
    "            }\n",
    "            headers = {\"User-Agent\": \"OlafJanssenBot/1.0 (https://commons.wikimedia.org/wiki/User:OlafJanssenBot; Python script)\"}\n",
    "            response = requests.get(SEARCH_URL, params=params, headers=headers).json()\n",
    "            results = response.get(\"query\", {}).get(\"search\", [])\n",
    "            all_titles.extend([\"File:\" + r[\"title\"].replace(\"File:\", \"\") for r in results])\n",
    "\n",
    "            if \"continue\" in response:\n",
    "                offset = response[\"continue\"][\"sroffset\"]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return all_titles\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search API call: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_balanced_template(wikitext, template_name):\n",
    "    \"\"\"\n",
    "    Extracts the full, balanced content of a template (e.g., {{Information}}), including nested templates and multiline fields.\n",
    "\n",
    "    Args:\n",
    "        wikitext (str): The full wikitext of a Commons file.\n",
    "        template_name (str): The name of the wrapper template to extract.\n",
    "\n",
    "    Returns:\n",
    "        str: The full matched template block, or empty string if not found.\n",
    "    \"\"\"\n",
    "    start = wikitext.lower().find(f'{{{{{template_name.lower()}')\n",
    "    if start == -1:\n",
    "        return ''\n",
    "\n",
    "    depth = 0\n",
    "    i = start\n",
    "    while i < len(wikitext) - 1:\n",
    "        if wikitext[i:i + 2] == '{{':\n",
    "            depth += 1\n",
    "            i += 2\n",
    "        elif wikitext[i:i + 2] == '}}':\n",
    "            depth -= 1\n",
    "            i += 2\n",
    "            if depth == 0:\n",
    "                return wikitext[start:i]\n",
    "        else:\n",
    "            i += 1\n",
    "    return ''\n",
    "\n",
    "\n",
    "def extract_templates_and_date(wikitext):\n",
    "    \"\"\"\n",
    "    Extracts all relevant templates and a simplified creation date from the given wikitext.\n",
    "\n",
    "    Supports:\n",
    "    - Wrapper templates like {{Information}}, {{Book}}, etc.\n",
    "    - Date fields like |date= and |publication date=\n",
    "    - Embedded permission-related templates\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            list[str]: A sorted list of relevant template names (e.g., [\"{{PD-old}}\", \"{{Anonymous-EU}}\"])\n",
    "            str: Parsed creation date (e.g., \"1930\", \"Early 20th century\", \"Unknown\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        all_templates = set()\n",
    "        creation_date = ''\n",
    "\n",
    "        for wrapper in WRAPPER_TEMPLATES:\n",
    "            wrapper_block = extract_balanced_template(wikitext, wrapper)\n",
    "            if wrapper_block:\n",
    "\n",
    "                # Extract |date= field (case-insensitive, allow spaces around =)\n",
    "                date_match = re.search(r'\\|\\s*[Dd]ate\\s*=\\s*(.+)', wrapper_block, re.IGNORECASE)\n",
    "                if date_match:\n",
    "                    raw_date = date_match.group(1).strip()\n",
    "                    date_for_parsing = raw_date.split('{{')[0].strip()\n",
    "                    creation_date = extract_year_from_date_string(date_for_parsing)\n",
    "\n",
    "                    # Also capture embedded templates in date\n",
    "                    embedded_templates = re.findall(r'\\{\\{([^\\|\\}\\n]+)', raw_date)\n",
    "                    for dt in embedded_templates:\n",
    "                        clean = f\"{{{{{dt.strip()}}}}}\"\n",
    "                        if not is_excluded_template(dt):\n",
    "                            all_templates.add(clean)\n",
    "\n",
    "                # If no creation_date yet, look for |publication date=\n",
    "                if not creation_date:\n",
    "                    pubdate_match = re.search(r'\\|\\s*[Pp]ublication\\s+date\\s*=\\s*(.+)', wrapper_block, re.IGNORECASE)\n",
    "                    if pubdate_match:\n",
    "                        raw_pubdate = pubdate_match.group(1).strip()\n",
    "                        pubdate_for_parsing = raw_pubdate.split('{{')[0].strip()\n",
    "                        creation_date = extract_year_from_date_string(pubdate_for_parsing)\n",
    "\n",
    "                        embedded_pub_templates = re.findall(r'\\{\\{([^\\|\\}\\n]+)', raw_pubdate)\n",
    "                        for dt in embedded_pub_templates:\n",
    "                            clean = f\"{{{{{dt.strip()}}}}}\"\n",
    "                            if not is_excluded_template(dt):\n",
    "                                all_templates.add(clean)\n",
    "\n",
    "                # Extract templates from |permission= field\n",
    "                permission_match = re.search(r'\\|\\s*[Pp]ermission\\s*=\\s*(.+?)(?=\\n\\||\\n*$)', wrapper_block, re.IGNORECASE | re.DOTALL)\n",
    "                if permission_match:\n",
    "                    permission_content = permission_match.group(1).strip()\n",
    "                    embedded_templates = re.findall(r'\\{\\{([^\\|\\}\\n]+)', permission_content)\n",
    "                    for t in embedded_templates:\n",
    "                        clean = f\"{{{{{t.strip()}}}}}\"\n",
    "                        if not is_excluded_template(t):\n",
    "                            all_templates.add(clean)\n",
    "\n",
    "        # Top-level templates (outside of wrappers)\n",
    "        top_level_matches = re.findall(r'^\\s*\\{\\{([^\\|\\}\\n]+)', wikitext, re.MULTILINE)\n",
    "        for t in top_level_matches:\n",
    "            clean = t.strip()\n",
    "            if not is_excluded_template(clean) and clean not in WRAPPER_TEMPLATES:\n",
    "                all_templates.add(f\"{{{{{clean}}}}}\")\n",
    "\n",
    "        return sorted(all_templates), creation_date\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting templates/date: {e}\")\n",
    "        return [], ''\n",
    "\n",
    "\n",
    "def process_templates_for_category(include_term, exclude_term):\n",
    "    \"\"\"\n",
    "    Main entry point: fetches Commons files in a target category and extracts template/date metadata.\n",
    "\n",
    "    Steps:\n",
    "    - Searches Commons for files in one category (e.g., \"Media from Delpher\") excluding another (e.g., \"Scans from the Internet Archive\").\n",
    "    - For each file, retrieves wikitext and parses relevant templates and creation dates.\n",
    "    - Outputs to console and saves results as an Excel file with URLs and template links.\n",
    "\n",
    "    Args:\n",
    "        include_term (str): Category to include (e.g., \"Media from Delpher\")\n",
    "        exclude_term (str): Category to exclude (e.g., \"Scans from the Internet Archive\")\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_titles = search_files_from_category_excluding_term(include_term, exclude_term)\n",
    "        file_titles = list(set(file_titles))  # Remove duplicates\n",
    "        records = []\n",
    "\n",
    "        for title in file_titles:\n",
    "            wikitext = get_wikitext(title)\n",
    "            file_url = \"https://commons.wikimedia.org/wiki/\" + urllib.parse.quote(title.replace(' ', '_'))\n",
    "            templates, creation_date = extract_templates_and_date(wikitext)\n",
    "\n",
    "            # Create (template, URL) pairs here\n",
    "            template_links = [\n",
    "                (tpl, f\"https://commons.wikimedia.org/wiki/Template:{tpl.strip('{}').replace(' ', '_')}\")\n",
    "                for tpl in templates\n",
    "            ]\n",
    "\n",
    "            # Console output\n",
    "            template_console = ', '.join([f\"{tpl} ({url})\" for tpl, url in template_links])\n",
    "            print(f\"{file_url} - {len(template_links)} - Date: {creation_date} - {template_console}\")\n",
    "\n",
    "            # Flatten for Excel: one row with file, date, template-URL pairs\n",
    "            row = [file_url, len(template_links), creation_date]\n",
    "            for tpl, url in template_links:\n",
    "                row.extend([tpl, url])\n",
    "            records.append(row)\n",
    "\n",
    "        if not records:\n",
    "            print(\"No valid files processed.\")\n",
    "            return\n",
    "\n",
    "        # Build Excel header\n",
    "        max_tpls = max((len(r) - 3) // 2 for r in records)  # each template = 2 columns\n",
    "        columns = ['File URL', 'NumberOfTemplates', 'DateOfCreation']\n",
    "        for i in range(max_tpls):\n",
    "            columns.extend([f'Template {i+1}', f'Template {i+1} URL'])\n",
    "\n",
    "        df = pd.DataFrame(records, columns=columns)\n",
    "\n",
    "        safe_category = include_term.replace(\" \", \"_\")  # \"Media_from_Delpher\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%d%m%Y\")\n",
    "        filename = f\"{safe_category}_commons_templates_output_{timestamp}.xlsx\"\n",
    "        df.to_excel(filename, index=False)\n",
    "        print(f\"Results written to {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing category: {e}\")\n",
    "\n",
    "\n",
    "# Entry point for script execution.\n",
    "# When run directly (not imported), it triggers the main processing workflow\n",
    "# and catches any unhandled exceptions at the top level.\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        include_term = \"Media from Delpher\"\n",
    "        exclude_term = \"Scans from the Internet Archive\"\n",
    "        process_templates_for_category(include_term, exclude_term)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a5f0c-690e-48e7-b0ca-08a3a1caf4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb96bf-bac8-40d3-8a67-4b6d06ad245f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
